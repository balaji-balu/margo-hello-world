# lo_fsm_resilient.yaml
initial_state: idle

meta:
  description: "Local Orchestrator FSM with resilience for intermittent network, LO crash, and node crash"
  timeout_seconds:
    monitor_heartbeat: 30   # seconds before considering node unreachable
    resync_retry: 10        # seconds between resync attempts
  retry_policy:
    resync_max_attempts: 5

events:
  # Normal deployment 
  
  - name: no_nodes_available
    src: ["idle", "pending", "recovering"]
    dst: waiting_for_nodes
    # Triggered when deployment is attempted but no nodes registered.

  - name: node_registered
    src: ["waiting_for_nodes"]
    dst: idle
    # Triggered when first node successfully registers.

  - name: node_registered_initial
    src: ["idle"]
    dst: idle
    # Allow node registration event to be handled gracefully when already idle.

  - name: receive_request
    src: ["idle"]
    dst: pending

  - name: start_deployment
    src: ["pending"]
    dst: deploying

  - name: nodes_all_running
    src: ["deploying"]
    dst: monitoring

  - name: node_failure
    src: ["monitoring"]
    dst: rollback

  - name: upgrade_site
    src: ["monitoring"]
    dst: upgrading

  - name: upgrade_success
    src: ["upgrading"]
    dst: monitoring

  - name: upgrade_fail
    src: ["upgrading"]
    dst: rollback

  - name: rollback_done
    src: ["rollback"]
    dst: monitoring

  - name: rollback_fail
    src: ["rollback"]
    dst: failed

  - name: reset
    src: ["failed", "monitoring", "rollback", "pending"]
    dst: idle

  # --- Resilience and recovery events ---

  # Intermittent connection to CO (or upstream)
  - name: connection_lost
    src: ["deploying", "monitoring", "upgrading", "pending"]
    dst: paused

  - name: connection_restored
    src: ["paused"]
    dst: monitoring

  # Node connectivity / heartbeat issues (node-level)
  - name: node_unreachable
    src: ["deploying", "monitoring", "upgrading"]
    dst: degraded
    # metadata hint: on enter -> schedule resync/query for that node

  - name: node_recovered
    src: ["degraded"]
    dst: monitoring

  - name: node_rejoined
    src: ["degraded", "monitoring"]
    dst: monitoring

  - name: node_crash_detected
    src: ["deploying", "monitoring", "upgrading"]
    dst: rollback
    # metadata hint: immediate rollback OR schedule based on policy

  # LO crash / restart recovery (rebuild state from persisted + node snapshots)
  - name: recover_state
    src: ["idle"]
    dst: recovering
    # This event is fired by LO on startup if persisted state exists

  - name: recovered_to_monitoring
    src: ["recovering"]
    dst: monitoring

  - name: recovered_to_deploying
    src: ["recovering"]
    dst: deploying

  - name: recovered_to_pending
    src: ["recovering"]
    dst: pending

  - name: resync
    src: ["recovering", "paused", "degraded"]
    dst: recovering
    # Use attempts counter from meta.retry_policy.resync_max_attempts

  # Explicit resync success/failure
  - name: resync_success
    src: ["recovering"]
    dst: monitoring

  - name: resync_failed
    src: ["recovering"]
    dst: failed

  # Administrative override: move LO into maintenance
  - name: enter_maintenance
    src: ["idle", "monitoring", "degraded", "failed"]
    dst: maintenance

  - name: exit_maintenance
    src: ["maintenance"]
    dst: idle
